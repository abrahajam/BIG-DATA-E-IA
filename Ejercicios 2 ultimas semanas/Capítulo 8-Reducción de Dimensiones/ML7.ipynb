{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706d03e7-0997-4e44-8d63-24815966bba0",
   "metadata": {},
   "source": [
    "# Capítulo 8: Reducción de Dimensionalidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a9c522-6f29-4c84-8cc7-a325b2472fe0",
   "metadata": {},
   "source": [
    "## Reducción de Dimensionalidad — Qué es y para qué sirve\n",
    "\n",
    "---\n",
    "\n",
    "## 1. PCA (Análisis de Componentes Principales)\n",
    "**Qué es:**  \n",
    "Un método de reducción de dimensionalidad que proyecta los datos en nuevas variables (componentes principales) que capturan la mayor parte de la variación del dataset.\n",
    "\n",
    "**Para qué sirve:**  \n",
    "- Reducir el número de características manteniendo la mayor información posible.  \n",
    "- Visualizar datos de alta dimensión.  \n",
    "- Acelerar modelos de machine learning al eliminar redundancia.  \n",
    "- Mitigar el ruido en los datos.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.1 PCA con Scikit-Learn\n",
    "**Qué es:**  \n",
    "La implementación de PCA en la librería scikit-learn, que calcula automáticamente los componentes principales y las proyecciones.\n",
    "\n",
    "**Para qué sirve:**  \n",
    "- Aplicar PCA de forma sencilla y eficiente.  \n",
    "- Integrarlo con pipelines y otros modelos de ML.  \n",
    "- Explorar cuánta varianza se retiene según la cantidad de componentes.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 PCA Incremental\n",
    "**Qué es:**  \n",
    "Una variante del PCA estándar que procesa los datos por lotes, sin necesidad de cargar todo el dataset en memoria.\n",
    "\n",
    "**Para qué sirve:**  \n",
    "- Trabajar con datasets muy grandes o que no caben en RAM.  \n",
    "- Realizar reducción de dimensionalidad en flujos continuos de datos.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Kernel PCA\n",
    "**Qué es:**  \n",
    "Una extensión no lineal de PCA que utiliza funciones kernel para proyectar los datos en un espacio de mayor dimensión donde patrones complejos pueden volverse lineales.\n",
    "\n",
    "**Para qué sirve:**  \n",
    "- Capturar estructuras no lineales que el PCA tradicional no puede.  \n",
    "- Mejorar tareas de clasificación o clustering tras la reducción.  \n",
    "- Visualizar datos con forma de espiral, curvas o patrones complejos.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1 Seleccionar un Kernel\n",
    "**Qué es:**  \n",
    "El proceso de elegir una función kernel (RBF, sigmoide, polinomial, etc.) para definir cómo se miden las similitudes en Kernel PCA.\n",
    "\n",
    "**Para qué sirve:**  \n",
    "- Controlar el tipo de transformación no lineal aplicada.  \n",
    "- Ajustar el modelo para detectar estructuras específicas en los datos.  \n",
    "- Mejorar la separación entre grupos o clases en el espacio reducido.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. LLE (Locally Linear Embedding)\n",
    "**Qué es:**  \n",
    "Un método de reducción de dimensionalidad no lineal que preserva las relaciones locales entre los puntos. En lugar de buscar componentes globales como PCA, se enfoca en reconstruir cada punto a partir de sus vecinos cercanos.\n",
    "\n",
    "**Para qué sirve:**  \n",
    "- Visualizar datos que se encuentran en variedades (manifolds) no lineales.  \n",
    "- Capturar estructuras complejas preservando la geometría local.  \n",
    "- Es especialmente útil cuando la forma de los datos es curva o intrincada (ej., \"Swiss roll\").\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdfd9bc-4139-493e-9ef0-9809b3457765",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">1. PCA</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd08539-0131-414a-879c-c92299463951",
   "metadata": {},
   "source": [
    "PCA=Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff72570a-df50-4427-9919-18101f4a1398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importa los librerías pandas, numpy, matplotlib, os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a9a664-e695-4a7e-91d6-59c8d59c88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trae los datos que necesitamos\n",
    "#candidates = {'gmat': [780,750,690,710,680,730,690,720,740,690,610,690,710,680,770,610,580,650,540,590,620,600,550,550,570,670,660,580,650,660,640,620,660,660,680,650,670,580,590,690],\n",
    "             # 'gpa': [4,3.9,3.3,3.7,3.9,3.7,2.3,3.3,3.3,1.7,2.7,3.7,3.7,3.3,3.3,3,2.7,3.7,2.7,2.3,3.3,2,2.3,2.7,3,3.3,3.7,2.3,3.7,3.3,3,2.7,4,3.3,3.3,2.3,2.7,3.3,1.7,3.7],\n",
    "             # 'work_experience': [3,4,3,5,4,6,1,4,5,1,3,5,6,4,3,1,4,6,2,3,2,1,4,1,2,6,4,2,6,5,1,2,4,6,5,1,2,1,4,5],\n",
    "             # 'admitted': [1,1,0,1,0,1,0,1,1,0,0,1,1,0,1,0,0,1,0,0,1,0,0,0,0,1,1,0,1,1,0,0,1,1,1,0,0,0,0,1]\n",
    "             # }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e984e52d-69d7-4256-ae16-6379e57b3466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separa el dataframe en los datos que vamos a utilizar para predecir y los datos predichos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d4793b-37c1-4217-9e09-4d7d940998e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Una vez teniendo nuestros datos centramos x restándole su media.\n",
    "\n",
    "#Recordemos que SVD descompone X en 3 matrices U, E y V por lo que utilizamos la función de numpy svd.\n",
    "\n",
    "#V es la que contiene los vectores con los componentes principales\n",
    "#para obtener los primeros 2 simplemente transponemos sus primeras 2 columnas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4146cb-9552-410e-ae19-2d66d2eeb0f7",
   "metadata": {},
   "source": [
    "Para proyectar nuestros datos en el hiperplano y obtener nuestra matriz X de dimensiones reducidas\n",
    "tenemos que XNUEVA = XW donde X es nuestra matriz de datos original y W es la matriz \n",
    "que contiene nuestros vectores de componentes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b533bae6-3287-4c47-8cee-2619a7b4877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c767b2-6363-4455-b618-b91508d18d36",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">1.1 Con Scikit</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b225056-b240-47db-9794-5653cba6a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importa PCA\n",
    "\n",
    "#Genera el objeto \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc96a6e4-46f5-49ed-abfa-9b16428e9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula la distribución de la varianza  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed54a393-f421-4ddd-b22d-1de13e343beb",
   "metadata": {},
   "source": [
    "Esta distribución nos indica la proporción de varianza que cada componente principal contiene en comparación al set de datos original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b067be89-ca4d-431a-9ec8-2eca0ad3cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea  un modelo donde tengas al menos el 90% de la varianza consevada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2349ee1d-e7c6-4398-9b41-993ee9198283",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73a5c55b-d8f9-4790-92b7-598b764df421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descomprime los datos con la función inverse_transform\n",
    "\n",
    "#Despliega el resultado de la descompresión\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395bde4-9b1c-4a9e-a633-557971e013b6",
   "metadata": {},
   "source": [
    "Se pierde fidelidad porque no explica la variación en todos los datos pero es suficiente para entrenar al algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86184122-f064-4fc7-bcbb-62fe931b3c34",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a2a10e-08db-41f1-b8e1-ca95b93ea193",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">1.2 PCA Incremental</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e19b3821-f386-4f61-9d93-f57bcc00f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importa IncrementalPCA\n",
    "\n",
    "#Divide los datos en 3, es decir, 3 subsets. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f93476-5111-4b2a-b3b7-ea24d88e4d39",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652b6bd-7af3-4f07-ba28-7f7716cdc56c",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">2. Kernel PCA</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "383ff89e-3e58-45f4-bd8c-1d6d610596e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importa KernelPCA\n",
    "\n",
    "#Haz un rbf= Radial Basis function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f54d45af-b710-4f7b-afb7-cda37099076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Visualiza los resultado \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f842ec7d-c335-418b-b0f1-696889ac026b",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">2.1 Seleccionar un Kernel</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60f25c1b-a8fc-4460-b9b8-577fa333a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importa GridSearchCV\n",
    "\n",
    "#Importa LogisticRegressin\n",
    "\n",
    "#Importa Pipeline\n",
    "\n",
    "\n",
    "#Arma un pipeline que pase por KernelPCA y LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8f6ecb6-5e2d-4c23-a12b-d030239477e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corre el GridSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b45f0461-5fda-4dae-ba22-eb2bf69679ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecuta el GridSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9615bba-6edd-4c1a-9d55-31c4136ffb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprime el mejor parámetro que equivale al PCA que será la mejor regresión logística\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1969c715-fdb3-419f-a290-e5706e16c4e9",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">2. LLE</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e092d2-6ad4-434e-9045-680334294cda",
   "metadata": {},
   "source": [
    "LLE= Locally Linear Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87099143-221a-4906-b399-bda8ed779fa6",
   "metadata": {},
   "source": [
    "Es un método de reducción de dimensionalidad no lineal y **no depende de proyecciones**\n",
    "\n",
    "Funciona midiendo como cada instancia de entrenamiento se relaciona linealmente con sus instancias vecinas y busca una representación lineal de pocas dimensiones del set de datos donde estas relaciones entre instancias cercanas o vecinas están bien preservadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39d0f66d-f611-4425-a417-654775b1f65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importa LocallyLinearEmbedding\n",
    "\n",
    "#Selecciona el número de dimensiones, componentes y \"vecinos\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7e6fae-c678-438d-b8ff-a538b7cac273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow (py310)",
   "language": "python",
   "name": "tf310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
