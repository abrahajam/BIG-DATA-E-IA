{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6c5f11",
   "metadata": {},
   "source": [
    "# Cap√≠tulo 4. Modelos de Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b19ad-a583-49d5-9972-a6c45916d16f",
   "metadata": {},
   "source": [
    "## Modelos de Entrenamiento ‚Äî Qu√© son y para qu√© sirven\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Regresi√≥n Lineal\n",
    "**Qu√© es:**  \n",
    "Un modelo que busca una relaci√≥n lineal entre variables predictoras y una variable objetivo.\n",
    "\n",
    "**Para qu√© sirve:**  \n",
    "- Predecir valores num√©ricos continuos.\n",
    "- Modelar relaciones simples entre variables.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.1 Ecuaci√≥n Normal\n",
    "**Qu√© es:**  \n",
    "Una f√≥rmula cerrada que calcula directamente los par√°metros √≥ptimos sin iteraciones.\n",
    "\n",
    "**Para qu√© sirve:**  \n",
    "- Entrenar regresi√≥n lineal de manera exacta.\n",
    "- Funciona bien con datasets peque√±os o medianos.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 Regresor Lineal de Scikit-Learn\n",
    "**Qu√© es:**  \n",
    "La implementaci√≥n en scikit-learn del modelo de regresi√≥n lineal.\n",
    "\n",
    "**Para qu√© sirve:**  \n",
    "- Entrenar modelos lineales f√°cilmente.\n",
    "- Integrarse con validaci√≥n, m√©tricas y pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Descenso del Gradiente\n",
    "**Qu√© es:**  \n",
    "Un m√©todo iterativo para optimizar par√°metros reduciendo el error paso a paso.\n",
    "\n",
    "**Para qu√© sirve:**  \n",
    "- Entrenar modelos cuando no existe soluci√≥n cerrada.\n",
    "- Escalar a grandes vol√∫menes de datos.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1 Descenso del Gradiente por Lote (Batch GD)\n",
    "**Qu√© es:**  \n",
    "Actualiza los par√°metros usando todo el dataset en cada iteraci√≥n.\n",
    "\n",
    "**Para qu√© sirve:**  \n",
    "- Obtener actualizaciones precisas y estables.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2 Descenso del Gradiente Estoc√°stico (SGD)\n",
    "**Qu√© es:**  \n",
    "Actualiza los par√°metros usando una sola muestra en cada iteraci√≥n.\n",
    "\n",
    "**Para qu√© sirve:**  \n",
    "- Entrenar r√°pidamente con datos grandes.\n",
    "- Explorar mejor el espacio de soluciones (aunque con m√°s ruido).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Regresi√≥n Polinomial\n",
    "**Qu√© es:**  \n",
    "Extiende la regresi√≥n lineal agregando t√©rminos polinomiales para capturar relaciones no lineales.\n",
    "\n",
    "**Para qu√© sirve:**  \n",
    "- Modelar curvas y patrones complejos.\n",
    "- Ajustar relaciones no lineales entre variables.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Curvas de Aprendizaje\n",
    "**Qu√© es:**  \n",
    "Gr√°ficos que muestran el rendimiento del modelo en funci√≥n del n√∫mero de ejemplos o iteraciones.\n",
    "\n",
    "**Para qu√© sirve:**  \n",
    "- Diagnosticar sobreajuste (overfitting) y subajuste (underfitting).\n",
    "- Decidir si se necesita m√°s datos o un modelo m√°s complejo.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Regularizaci√≥n de Modelos Lineales\n",
    "**Qu√© es:**  \n",
    "M√©todos que penalizan par√°metros grandes para evitar sobreajuste.\n",
    "\n",
    "**Para qu√© sirve:**  \n",
    "- Mejorar la capacidad de generalizaci√≥n.\n",
    "- Controlar la complejidad del modelo.\n",
    "\n",
    "---\n",
    "\n",
    "### 5.1 Ridge (Regularizaci√≥n L2)\n",
    "**Qu√© es:**  \n",
    "Penalizaci√≥n basada en el cuadrado de los coeficientes.\n",
    "\n",
    "**Para qu√© sirve:**  \n",
    "- Reducir sobreajuste manteniendo coeficientes peque√±os.\n",
    "- Funciona bien con variables correlacionadas.\n",
    "\n",
    "---\n",
    "\n",
    "### 5.2 Lasso (Regularizaci√≥n L1)\n",
    "**Qu√© es:**  \n",
    "Penalizaci√≥n basada en la suma de los valores absolutos de los coeficientes.\n",
    "\n",
    "**Para qu√© sirve:**  \n",
    "- Realizar selecci√≥n de caracter√≠sticas (coeficientes se vuelven cero).\n",
    "- Simplificar modelos autom√°ticamente.\n",
    "\n",
    "---\n",
    "\n",
    "### 5.3 Elastic Net\n",
    "**Qu√© es:**  \n",
    "Combinaci√≥n de las penalizaciones L1 y L2.\n",
    "\n",
    "**Para qu√© sirve:**  \n",
    "- Aprovechar beneficios de Ridge y Lasso.\n",
    "- Manejar datasets con variables muy correlacionadas.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Regresi√≥n Log√≠stica\n",
    "**Qu√© es:**  \n",
    "Modelo lineal que utiliza la funci√≥n sigmoide para estimar probabilidades.\n",
    "\n",
    "**Para qu√© sirve:**  \n",
    "- Resolver problemas de clasificaci√≥n binaria.\n",
    "- Interpretar resultados como probabilidades.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Regresi√≥n Softmax\n",
    "**Qu√© es:**  \n",
    "Extensi√≥n de la regresi√≥n log√≠stica para m√∫ltiples clases.\n",
    "\n",
    "**Para qu√© sirve:**  \n",
    "- Clasificaci√≥n multiclase.\n",
    "- Modelos donde las clases son mutuamente excluyentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aea9ac",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">1. Regresi√≥n Lineal</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae840a-8ec4-4aa0-ae6b-4d43d5dfc05a",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\"> 1.1 Ecuaci√≥n Normal </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a6195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librer√≠as, numpy, matplotlib, pandas\n",
    "# numpy es la bibleoteca por exelencia de matem√°ticas para python\n",
    "\n",
    "#Importar matplotlib porque vamos a estar haciendo gr√°ficas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1e8b47-8c1f-4b16-bca8-db08b28e9d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar el set de jueguete de datos lineales aleatorios \n",
    "\n",
    "\n",
    "#Genera vector de valores que vas a estar prediciendo (a√±ade un factor de aleatoriedad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67cbbac0-bb3c-446f-aa7e-a917fa222404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gr√°fica los datos del set de juguete \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8192492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregar el valor de x0\n",
    "\n",
    "#Aplicar la ecuaci√≥n normal \n",
    "\n",
    "#Visualiza  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dae9649-e147-4b33-ac91-04c432acd125",
   "metadata": {},
   "source": [
    "üëÄ: Aqu√≠ no tendr√°n los mismos datos que yo, es normal por los factores de aleatoriedad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a8d2d6-667b-49f1-9b23-66d26f11798c",
   "metadata": {},
   "source": [
    "üìù:El primer valor de la matriz es la pendiente y el segundo es la intersecci√≥n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c44c9e-61ea-4112-b198-bc1a128a8e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba estes datos con un vector de prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "955f34b4-96b8-4f14-b461-57e75328ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregar X0=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba827be2-7e12-4f90-8d8c-c8cb3e50c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer las predicciones con la ecuaci√≥n normal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "249e3f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafica la regresi√≥n con los datos originales y la predicci√≥n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d2741-8ce2-4e82-844a-d352901b4e8c",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\"> 1.2 Regresor Linear de Scikit </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a06bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Haz la regresi√≥n con scikit \n",
    "\n",
    "\n",
    "\n",
    "#C√°lcula la intersecci√≥n y la pendiente con este m√©todo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a45cd5-3827-4ecf-b6d4-75c3ce1ce6cd",
   "metadata": {},
   "source": [
    "Los par√°metros son iguales a los que obtuvimos en el m√©todo anterior. En este caso, tendr√≠as que evaluar el costo que implica cada m√©todo a tu ordenador. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d0ac17-eb12-48e3-b47b-92f6f080a81a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f25b06",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">2. Descenso del Gradiente</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14cd517-3801-4ebc-8d4d-48051abfefac",
   "metadata": {},
   "source": [
    "Algoritmo de optimizaci√≥n. Signfica una alternativa a la ecuaci√≥n normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d3f85f",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\"> 2.1 Descenso del Gradiente por Lote</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78413dea-6574-4c6f-ad8a-9f8f3ab94df5",
   "metadata": {},
   "source": [
    "**Derivada parcial de la funci√≥n de costo (MSE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aec6a4",
   "metadata": {},
   "source": [
    "$ \\frac{\\partial}{\\partial b} J(b) = \\frac{2}{m} \\sum_{i=1}^{m}(b^Tx^i-y^i)x^i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20388e85-5bde-47df-b2fb-62ba717e78d2",
   "metadata": {},
   "source": [
    "**Vector del Gradiente de la funci√≥n de costo** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9bab83",
   "metadata": {},
   "source": [
    "$ \\bigtriangledown_b MSE(b) = [\\frac{\\partial}{\\partial b_1} MSE(b_1), \\frac{\\partial}{\\partial b_2} MSE(b_2) ,....\\frac{\\partial}{\\partial b_m} MSE(b_m)] = \\frac{2}{m} X^T(Xb-y) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b0a17-d5d0-49fb-be8a-7fc9f5095e5b",
   "metadata": {},
   "source": [
    "**Step del descenso del Gradiente**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ea077",
   "metadata": {},
   "source": [
    "$ b^{+} = b-n\\bigtriangledown_b MSE(b) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98d3201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la tasa de aprendizaje (ra=(valor que queramos darle))\n",
    "\n",
    "#Definir las iteraciones. 1000 es un est√°ndar. En 1000 se va a detener\n",
    "\n",
    "#N√∫mero de datos \n",
    "\n",
    "#Incializa la pendiente \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d05a46-4945-468f-abe4-92d772968f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer el programa para el descenso del gradiente\n",
    "\n",
    "    #Expresi√≥n a manera de √°gebra lineal de los m√≠nimos cuadrados (funci√≥n de costo)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb50f1-afaf-47cb-90c7-410214f3c1b4",
   "metadata": {},
   "source": [
    "Los resultados nos da extremadamente cercano a los datos obtenidos con la ecuaci√≥n normal. Ojo: recuerda que el descenso del gradiente es un m√©todo de aproximaci√≥n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6bfb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repetir el ejercicio pero con ritmo de tasa de aprendizaje diferente \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Visualiza los modelos que va proponiendo hasta llegar a la predicci√≥n final \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61216a12-0170-44f9-b8a6-4c915b0e7e1c",
   "metadata": {},
   "source": [
    "**Ejercicio Extra**: Var√≠a la tasa de aprendizaje y los n√∫mero de pasos para observar como funciona el gradiente de tipo batch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e438fca-35e2-48e3-a1e3-9a9261cedc2f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b94ab7",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\"> 2.2 Descenso del Gradiente Estoc√°stico</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bfb053-02de-4b03-8be2-6c86aaf2847d",
   "metadata": {},
   "source": [
    "Debido a qu√© la complejidad computacional del descenso del gradiente de lote es alto, podemos ver el descenso del gradiente estoc√°stico para poder mejorar las predicci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d56df3c-0576-433f-b4a2-2b9780cc9385",
   "metadata": {},
   "source": [
    "**Ventajas**: Puedes trabajar con m√°s datos, escapa de los m√≠nimos locales. \n",
    "**Desventajas:** No es tan exacto como los otros m√©todos. Sin embargo, su variaci√≥n es despreciable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "576289e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs: cu√°ntas gradientes har√°, cu√°ntos datos seleccionar√° para hacer el gradiente \n",
    "\n",
    "#Calendario de aprendizaje, sirve para definir el ritmo de aprendizaje\n",
    "\n",
    "#Definir el horario de aprendizaje\n",
    "\n",
    "#Definir los 2 valores con lo que van a empezar\n",
    "\n",
    "\n",
    "#Definir la funci√≥n \n",
    "\n",
    "        #Genera un √≠ndice aleatorio\n",
    "        \n",
    "        #Valor x de la coordenada que seleccionamos al azar\n",
    "\n",
    "        #Valor y de la coordenada que seleccionamos al azar\n",
    "\n",
    "        #Calcular el gradiente (Resultado de la derivada parcial)\n",
    "\n",
    "        #Calcular el ritmo de aprendizaje\n",
    "\n",
    "        #Calcular los par√°metros de intersecci√≥n y pendiente \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb8eb3b-4929-46d2-8ae4-ec3d6aea2129",
   "metadata": {},
   "source": [
    "Aunque existe variaci√≥n con el resultado de los m√©todos anteriores, la diferencia es m√≠nima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a6140bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Repetir el ejercicio pero desplegando cada gradiente realizado \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Agrega un scatterplot para ver los datos \n",
    "\n",
    "        #Grafica las l√≠neas rojas que simbolizan los diferentes gradientes a trav√©s de las iteraciones. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a46f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacerlo con scikit \n",
    "\n",
    "#La toleraci√≥n es el l√≠mite menor al valor de la suma de los errores al cuadrado \n",
    "\n",
    "#.ravel: te genera una lista normal \n",
    "\n",
    "#Sacar los par√°metros, la intersecci√≥n y la pendiente \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24cb1db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualiza la lista normal que genera .ravel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed3539f-0646-4995-b4f1-5eaf15fcf45e",
   "metadata": {},
   "source": [
    "üëÄ: Con este m√©todo si existi√≥ una variaci√≥n importante en los resultados obtenidos. Es cuesti√≥n de criterio el sacrificar exactitud por costo computacional o viceversa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6b0333-0bf4-4f04-84fd-bdcc47c265b1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575b86d9",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">3. Regresi√≥n polinomial</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8025797f-0d5f-49c3-97b2-5230ca2bae8b",
   "metadata": {},
   "source": [
    "Regresi√≥n polinomial es una regresi√≥n linel a la cual le agregamos ecuaciones con potencia m√°s elevada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cb73669-c866-4dc9-8100-c9d62b9c6dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar set de datos de juguete. A√±ade un toque de aleatoriedad\n",
    "\n",
    "#Elevar la ecuaci√≥n al 2\n",
    "\n",
    "#Gr√°fica el set de datos \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013813e7-4d0d-4ee0-9022-8b839a701026",
   "metadata": {},
   "source": [
    "No hay una funci√≥n en scikit para hacer regresiones polinomiales como tal. Pero podemos utilizar PolynomialFeature que toma los valores de x y los eleva a una potencia especificada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "095ef814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar PolynomialFeatures con una potencia 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e3d7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer una regresi√≥n lineal sobre de los datos \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79d7127-016a-482d-81f1-ac4ea96060dc",
   "metadata": {},
   "source": [
    "Primero aparece el dato de la intersecci√≥n y luego aparece los coeficientes de de x y x2, respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4fddf3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Graficar la predicci√≥n de PolynomialFeatures y los datos originales\n",
    "\n",
    "#escribir la f√≥rmula a partir del array de arriba \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008e81d3-cf68-4a9f-ada7-0190369939e5",
   "metadata": {},
   "source": [
    "**Ejercicio**: calcular la suma de los errores al cuadrado  y compararlo con una predicci√≥n lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3358f3-5746-455b-a069-ca4c4baeda06",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d314b",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">4. Curvas de Aprendizaje</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ed166a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar mean_squared_error train_test_split para medir el error sobre los datos de entranamiento y validaci√≥n\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Empezamos dividiendo los datos en datos de entrenamiento y validaci√≥n \n",
    "\n",
    "    #Generar una lista vac√≠as para irlas rellenando conforme se vaya calculando los errores \n",
    "\n",
    "    #Tomar el set de entrenamiento y ajust√°ndolo al modelo pero solo con un dato de entrenamiento y as√≠ sucesivamente \n",
    "   \n",
    "        #predecir el modelo \n",
    "\n",
    "        #predecir el modelo\n",
    "\n",
    "        #Calcular los errores\n",
    "\n",
    "\n",
    "        \n",
    "        #graficarlos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f8998e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correr la curva de aprendizaje\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64f0116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer un pipeline llamado regresion_polinomial que haga una regresi√≥n polinomial y lineal \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e4c52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutar curvas de aprendizaje a regresion_polinomial \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54a74efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variar el grado del polinomio para mejorar el rendimiento del modelo. Ejemplo:2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf638578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correr la curva de aprendizaje\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db34acd7-2733-4a91-b7f6-d783c6088ebe",
   "metadata": {},
   "source": [
    "Generalemnte, cuando las l√≠nas se tocan signfica que llegaste a un buen modelo. No esta sobreajustado ni subajustado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f8f982-8def-4987-887e-54e80384c567",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d27ee",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">5. Regularizaci√≥n de Modelos lineales</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0decaad2",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">5.1 Regresi√≥n de Ridge o de Cresta</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3727cc74-8372-482e-a6a4-53dbef4e5f5a",
   "metadata": {},
   "source": [
    "**T√©rmino de regularizaci√≥n en la regresi√≥n de Ridge**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb5330",
   "metadata": {},
   "source": [
    "$ \\alpha \\sum_{i=1}^{m} b_i^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e18327-e749-423d-b5b0-e1e587936f26",
   "metadata": {},
   "source": [
    "**Funci√≥n de costo de la regresi√≥n de Ridge**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4defe626",
   "metadata": {},
   "source": [
    "$ MSE(b) + \\alpha \\frac{1}{2} \\sum_{i=1}^{m} b^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67bf0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer un set de juguete \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79b92fa2-d658-4f43-932b-9c1a0976b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer una regresi√≥n lineal sencilla para comparar con la regresi√≥n de cresta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a174ac4b-25fd-43bd-8fd2-05b7bf06f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar 100 datos para graficar la linea de predicci√≥n  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baecf0d7-f773-45d1-a96a-f8205e98fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficar \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3b74a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar Ridge para hacer nuestra regresi√≥n de cresta \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9df1065f-a018-4fae-950f-7b9b3ab18fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula los par√°metros de ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d063181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer la linea de la predicci√≥n de Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aef913a1-5fa8-4d5d-ab50-ab8c4de09c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficar comparando la regresi√≥n lineal y de Ridge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c50bf-7504-43f5-9e59-9bf9ce8dd71b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a4f6d5",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">5.2 Regresi√≥n de Lasso</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5b598-2f6d-4935-a50c-0bcf2bb946d7",
   "metadata": {},
   "source": [
    "**Funci√≥n de costo de la regresi√≥n de regresi√≥n de Lasso**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db27124",
   "metadata": {},
   "source": [
    "$ MSE(b) + \\alpha  \\sum_{i=1}^{m} |b| $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51c85c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar lasso\n",
    "\n",
    "#Asignar una alpha de 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de2b40c1-7159-4142-a08c-496bec4f0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular los par√°metros de intersecci√≥n y coeficientes de x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd7f1156-9f81-42a4-a153-cd41dfd858e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer la linea de la predicci√≥n de lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6deeb45-fb11-418a-9673-73396e9c617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficar comparando la regresi√≥n lineal, de Ridge y de Lasso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8d74d1-912c-41e7-9927-fe1f591869ac",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d756eb74",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">5.3 Regresi√≥n de Red El√°stica</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22129521-93ae-4487-8a73-a5eb3bc3d38a",
   "metadata": {},
   "source": [
    "**Funci√≥n de costo de la Regresi√≥n de Red El√°stica**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff47ef80",
   "metadata": {},
   "source": [
    "$ MSE(b) + r\\alpha  \\sum_{i=1}^{m} |b| + \\alpha \\frac{1-r}{2} \\sum_{i=1}^{m} b^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "623b4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar ElasticNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c71769a8-f3e5-4dbe-b601-5e6f69366322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular los par√°metros de intersecci√≥n y coeficientes de x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c102a31b-4e88-4916-85e2-0034602c6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer la linea de la predicci√≥n de Red El√°stica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02a7b0da-d682-4d3f-ab9c-c6521715f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficar comparando la regresi√≥n lineal, de Ridge, de Lasso y de Red El√°stica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e78a98-5351-4126-af75-9b947fc9023b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd50fab",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">6. Regresi√≥n Logistica</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861cafe9-3e1a-4d4a-9e01-e745b76f6e25",
   "metadata": {},
   "source": [
    "**Modelo de Regresi√≥n Log√≠stica**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7046cd",
   "metadata": {},
   "source": [
    "$ \\hat{p} = L(b^Tx) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a978442-9efe-4255-875e-6438b95e7605",
   "metadata": {},
   "source": [
    "**Funci√≥n log√≠stica**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c30dad",
   "metadata": {},
   "source": [
    "$ L = \\frac {1}{1+e^{-t}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551c2845-a13f-4036-85cb-a31a6006d8dd",
   "metadata": {},
   "source": [
    "**Funci√≥n de Costo de la Regresi√≥n Log√≠stica**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8f5150",
   "metadata": {},
   "source": [
    "$ J(b) = \\frac{1}{m} \\sum_{i=1}^{m}[ylog(\\hat p)+(1-y)log(1-\\hat p)] $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8928b99-4431-4d56-acac-d8224ee5c2c7",
   "metadata": {},
   "source": [
    "**Derivada de la funci√≥n de Costo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a732be7e",
   "metadata": {},
   "source": [
    "$ \\frac{\\partial}{\\partial b} J(b) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae5f4a12",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1163543574.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [43]\u001b[0;36m\u001b[0m\n\u001b[0;31m    }\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#Traer el set de datos\n",
    "#candidates = {'gmat': [780,750,690,710,680,730,690,720,740,690,610,690,710,680,770,610,580,650,540,590,620,600,550,550,570,670,660,580,650,660,640,620,660,660,680,650,670,580,590,690],\n",
    " #             'gpa': [4,3.9,3.3,3.7,3.9,3.7,2.3,3.3,3.3,1.7,2.7,3.7,3.7,3.3,3.3,3,2.7,3.7,2.7,2.3,3.3,2,2.3,2.7,3,3.3,3.7,2.3,3.7,3.3,3,2.7,4,3.3,3.3,2.3,2.7,3.3,1.7,3.7],\n",
    "  #            'work_experience': [3,4,3,5,4,6,1,4,5,1,3,5,6,4,3,1,4,6,2,3,2,1,4,1,2,6,4,2,6,5,1,2,4,6,5,1,2,1,4,5],\n",
    "   #           'admitted': [1,1,0,1,0,1,0,1,1,0,0,1,1,0,1,0,0,1,0,0,1,0,0,0,0,1,1,0,1,1,0,0,1,1,1,0,0,0,0,1]\n",
    "              }\n",
    "#Visualizar el set de datos \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f4d72c-8c48-4eae-bb41-237ee2de51d7",
   "metadata": {},
   "source": [
    "**KEY:** \n",
    "gmat: prueba de coeficiente intelectual\n",
    "gpa: es tu promedio en la escuela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir el set de datos en en las variables predichas y la variable a predecir \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501807ff-dfcc-4e86-b5e8-06b8b4f78b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer las predicciones \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5e512-4860-43f5-beb3-35dea68a8f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualiza y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e7892-64b0-4a3f-a320-2a831c46affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizar la funci√≥n predict_proba para visualizar la probabilidad de que sea admitido \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39f3e9-462c-4294-95b5-53d75b73be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar una lista para ver la probabilidad de ser admitidos y a los que no \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab37afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incluir estas listas en nuestro dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd8e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizar el peso de la experiencia laboral, de gmat y de gpa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e025be-e461-45e8-b14f-a41c135d8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluar la regresi√≥n con m√©tricas como la matriz de confusi√≥n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb2f9a-668b-4a91-99ea-3911ea311b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluar la regresi√≥n con m√©tricas como f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ab8a8",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">6. Regresi√≥n Softmax</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e45005",
   "metadata": {},
   "source": [
    "$ claseA(x) = (b^A)^T x $\n",
    "\n",
    "$ claseB(x) = (b^B)^T x $\n",
    "\n",
    "$ claseC(x) = (b^C)^T x $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf8ac9",
   "metadata": {},
   "source": [
    "$\\hat p_A = L(claseA(x)) $\n",
    "\n",
    "$ \\hat p_B = L(claseB(x))$\n",
    "\n",
    "$ \\hat p_C = L(claseC(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709f33ac",
   "metadata": {},
   "source": [
    "$ L = \\frac{e^x}{\\sum_{i=1}^{m} e^x }  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3633831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar LogisticRegression\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow (py310)",
   "language": "python",
   "name": "tf310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
